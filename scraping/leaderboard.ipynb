{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from src.leaderboard.read_evals import EvalResult\n",
    "\n",
    "datadir = '/home/alex/Downloads/open-llm-leaderboard/'\n",
    "outputdir = '/home/alex/Dropbox/Code/my-repos/metabench/scraping/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 1171 users with in total 5821 models.\n"
     ]
    }
   ],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self, root: str):\n",
    "        self.root = root\n",
    "        self._loadUsers()\n",
    "        self._loadModels()\n",
    "        self._loadResults()\n",
    "        self._cleanUsers()\n",
    "        self._countModels()\n",
    "        self.n_failed = 0\n",
    "        self.n_incomplete = 0\n",
    "        print(f'Fetched {self.nUsers} users with in total {self.nModels} models.')\n",
    "            \n",
    "    def _loadUsers(self):\n",
    "        users = os.listdir(self.root)\n",
    "        users = [u for u in users if u[0] != '.' if os.path.isdir(os.path.join(self.root, u))]\n",
    "        self.nUsers = len(users)\n",
    "        self.data = dict.fromkeys(sorted(users))\n",
    "    \n",
    "    def _loadModels(self):\n",
    "        for user in self.data:\n",
    "            models = os.listdir(os.path.join(self.root, user))\n",
    "            self.data[user] = dict.fromkeys(sorted(models))\n",
    "    \n",
    "    def _loadResults(self):\n",
    "        self.flat_users = []\n",
    "        for user in self.data:\n",
    "            for model in self.data[user]:\n",
    "                path = os.path.join(self.root, user, model)\n",
    "                if not os.path.isdir(path):\n",
    "                    self.flat_users.append(user)\n",
    "                    continue\n",
    "                self.data[user][model] = sorted(os.listdir(path))\n",
    "\n",
    "    def _cleanUsers(self):\n",
    "        self.flat_users = list(set(self.flat_users))\n",
    "        for user in self.flat_users:\n",
    "            self.data[user] = list(self.data[user].keys())\n",
    "    \n",
    "    def _countModels(self):\n",
    "        self.nModels = 0\n",
    "        for user in self.data:\n",
    "            self.nModels += len(self.data[user])\n",
    "    \n",
    "    def _sortJsons(self, jsons: List[str]) -> List[str]:\n",
    "        # Sort the files by date\n",
    "        try:\n",
    "            jsons.sort(key=lambda x: x.removesuffix(\".json\").removeprefix(\"results_\")[:-7])\n",
    "        except ValueError:\n",
    "            print('Warning: Could not sort jsons by date.')\n",
    "        return jsons\n",
    "        \n",
    "    def _getFilePaths(self, user: str, model: str) -> List[str]:\n",
    "        files = self.data[user] if user in self.flat_users else self.data[user][model]\n",
    "        files = self._sortJsons(files)\n",
    "        if user in self.flat_users:\n",
    "            return [os.path.join(self.root, user, file) for file in files]\n",
    "        return [os.path.join(self.root, user, model, file) for file in files]\n",
    "        \n",
    "    def parseJson(self, user: str, model: str) -> dict:\n",
    "        paths = self._getFilePaths(user, model)\n",
    "        # while there are paths, try to load the jsons\n",
    "        # if successful, return the dict, otherwise try next path\n",
    "        while len(paths) > 0:\n",
    "            path = paths.pop()\n",
    "            try:\n",
    "                out = EvalResult.init_from_json_file(path)\n",
    "                summary = {\n",
    "                    'name': out.full_model,\n",
    "                    'link': f'https://huggingface.co/{out.full_model}',\n",
    "                    'complete': len(out.results) == 6,\n",
    "                    'avg': sum(out.results.values()) / len(out.results),\n",
    "                    'arc': None if 'arc:challenge' not in out.results else out.results['arc:challenge'],\n",
    "                    'hellaswag': None if 'hellaswag' not in out.results else out.results['hellaswag'],\n",
    "                    'mmlu': None if 'hendrycksTest' not in out.results else out.results['hendrycksTest'],\n",
    "                    'truthfulqa': None if 'truthfulqa:mc' not in out.results else out.results['truthfulqa:mc'],\n",
    "                    'winogrande': None if 'winogrande' not in out.results else out.results['winogrande'],\n",
    "                    'gsm8k': None if 'gsm8k' not in out.results else out.results['gsm8k'],\n",
    "                    'available': out.still_on_hub,\n",
    "                    'merged': out.is_merge,\n",
    "                    'flagged': out.flagged,\n",
    "                    'moe': (\"moe\" in out.tags if out.tags else False) or \"moe\" in out.full_model.lower(),\n",
    "                    'sha': out.revision,\n",
    "                    'precision': out.precision.value.name,\n",
    "                    }\n",
    "                \n",
    "                # # Sanity check\n",
    "                # number_of_nones = sum([1 for v in summary.values() if v is None])\n",
    "                # if (6 - number_of_nones) != len(out.results):\n",
    "                #     print(f'Something went wrong with {path}: nubmer of nones: {number_of_nones}, len of results: {len(out.results)}')\n",
    "                return summary\n",
    "\n",
    "            except:\n",
    "                # print(f'Could not load {path}')\n",
    "                self.n_failed += 1\n",
    "                pass\n",
    "        print(f'No complete data set for {user}/{model}')\n",
    "        return {}\n",
    "    \n",
    "    def toDataFrame(self) -> None:\n",
    "        dicts = []\n",
    "        for user in self.data:\n",
    "            for model in self.data[user]:\n",
    "                summary = self.parseJson(user, model)\n",
    "                if len(summary) > 0:\n",
    "                    dicts.append(summary)\n",
    "        self.df = pd.DataFrame(dicts)\n",
    "        self.n_incomplete = len(self.df[self.df['complete'] == False])\n",
    "        print(f'Created DataFrame with {len(dicts)} entries. {self.n_failed} models could not be loaded. {self.n_incomplete} models are incomplete.')\n",
    "        \n",
    "    def dump2csv(self, path: str) -> None:\n",
    "        self.df.to_csv(path, index=False)\n",
    "        print(f'Dumped DataFrame to {path}')\n",
    "        \n",
    "    def dump2pickle(self, path: str) -> None:\n",
    "        self.df.to_pickle(path)\n",
    "        print(f'Dumped DataFrame to {path}')\n",
    "        \n",
    "dl = Dataloader(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '01-ai/Yi-34B',\n",
       " 'link': 'https://huggingface.co/01-ai/Yi-34B',\n",
       " 'complete': False,\n",
       " 'avg': 66.83760448499348,\n",
       " 'arc': None,\n",
       " 'hellaswag': None,\n",
       " 'mmlu': None,\n",
       " 'truthfulqa': None,\n",
       " 'winogrande': 83.03078137332281,\n",
       " 'gsm8k': 50.644427596664144,\n",
       " 'available': True,\n",
       " 'merged': False,\n",
       " 'flagged': False,\n",
       " 'moe': False,\n",
       " 'sha': '7326a5806e10f34e60888947792b311dddb22590',\n",
       " 'precision': 'bfloat16'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = '01-ai'\n",
    "model = 'Yi-34B'\n",
    "out = dl.parseJson(user, model)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created DataFrame with 5821 entries. 0 models could not be loaded. 1848 models are incomplete.\n"
     ]
    }
   ],
   "source": [
    "dl.toDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumped DataFrame to /home/alex/Dropbox/Code/my-repos/metabench/scraping/open-llm-leaderboard.csv\n"
     ]
    }
   ],
   "source": [
    "dl.dump2csv(os.path.join(outputdir, 'open-llm-leaderboard.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metabench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
